import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import joblib

# ----------------- Paths -----------------
input_file = "C:/Users/rkpha/Desktop/cardekho/app/MERGED_ALL.csv"
output_folder = "C:/Users/rkpha/Desktop/cardekho/app/"

# ----------------- Load Data -----------------
df = pd.read_csv(input_file)

target = 'price(in lakhs)'
X = df.drop(columns=[target])
y = df[target]

# Separate numeric and categorical
num_cols = ["km", "ownerNo", "modelYear", "engineCC"]
cat_cols = [col for col in X.columns if col not in num_cols]

X_numeric = X[num_cols]
X_categorical = X[cat_cols].fillna("Missing")  # ðŸ”¥ FIX: Fill missing categorical values

# ----------------- Preprocessing -----------------
imputer = SimpleImputer(strategy='median')
X_numeric_imputed = imputer.fit_transform(X_numeric)

scaler = MinMaxScaler()
X_numeric_scaled = scaler.fit_transform(X_numeric_imputed)

X_numeric_final = pd.DataFrame(X_numeric_scaled, columns=num_cols)
X_categorical_final = pd.get_dummies(X_categorical)

# Merge numeric + categorical
X_final = pd.concat([X_numeric_final.reset_index(drop=True), X_categorical_final.reset_index(drop=True)], axis=1)

# Normalize target
price_min = y.min()
price_max = y.max()
y_scaled = (y - price_min) / (price_max - price_min)

# ----------------- Train-Test Split -----------------
X_train, X_test, y_train, y_test = train_test_split(X_final, y_scaled, test_size=0.2, random_state=42)

# ----------------- Train Multiple Models -----------------
models = {
    "Linear Regression": LinearRegression(),
    "Ridge Regression": Ridge(),
    "Decision Tree": DecisionTreeRegressor(random_state=42),
    "Random Forest": RandomForestRegressor(n_estimators=100, random_state=42),
    "Gradient Boosting": GradientBoostingRegressor(n_estimators=100, random_state=42)
}

results = []

for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)

    mae = mean_absolute_error(y_test, preds)
    mse = mean_squared_error(y_test, preds)
    r2 = r2_score(y_test, preds)

    results.append({
        "Model": name,
        "MAE": mae,
        "MSE": mse,
        "R2 Score": r2
    })

# ----------------- Display Results -----------------
results_df = pd.DataFrame(results).sort_values(by='R2 Score', ascending=False)
print("ðŸ”µ Model Performance Comparison:")
print(results_df)

# ----------------- Save Best Model -----------------
best_model_name = results_df.iloc[0]['Model']
print(f"\nâœ… Best Model Selected: {best_model_name}")

best_model = models[best_model_name]
best_model.fit(X_train, y_train)

# Save model and preprocessing objects
joblib.dump(best_model, output_folder + "best_model.pkl")
joblib.dump(imputer, output_folder + "imputer.pkl")
joblib.dump(scaler, output_folder + "scaler.pkl")
joblib.dump({'min': price_min, 'max': price_max}, output_folder + "price_range.pkl")

print("\nðŸ“‚ Model, imputer, scaler, and price range saved successfully!")
